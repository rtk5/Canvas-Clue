{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9816574,"sourceType":"datasetVersion","datasetId":6018648}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Question \n\nWe have to find the location of the theft! We are given a dataset of images (cats and dogs). The test dataset consists of 2 images which we need to decode. We have 4 locations (00, 01, 10 & 11) and the theft will occur in one of these places. Use a CNN model to analyse the dataset and feed the test data to recieve your final answer.","metadata":{}},{"cell_type":"code","source":"# Importing necessary modules.\n\nimport tensorflow as tf\nimport os\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom keras import datasets, layers, models\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D , MaxPooling2D , Dense , Flatten , Dropout\nimport cv2\nimport imghdr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:00:48.911093Z","iopub.execute_input":"2024-11-05T19:00:48.911814Z","iopub.status.idle":"2024-11-05T19:01:07.5536Z","shell.execute_reply.started":"2024-11-05T19:00:48.911754Z","shell.execute_reply":"2024-11-05T19:01:07.552298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Directory containing the dataset.\n\ndata_dir = \"/kaggle/input/final-dataset/dataset_1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:10.836171Z","iopub.execute_input":"2024-11-05T19:01:10.836964Z","iopub.status.idle":"2024-11-05T19:01:10.842567Z","shell.execute_reply.started":"2024-11-05T19:01:10.836914Z","shell.execute_reply":"2024-11-05T19:01:10.84115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Only images of these format should be present. Everything else like .gif etc will be removed.\n\nimage_exts = ['jpeg' , 'jpg' , 'bmp' , 'png']\n\nfor image_class in os.listdir(data_dir):\n    for image in os.listdir(os.path.join(data_dir , image_class)):\n        image_path = os.path.join(data_dir , image_class , image)\n        try: \n            img = cv2.imread(image_path)\n            tip = imghdr.what(image_path)\n            if tip not in image_exts:\n                print(\"Image not in ext list {}\".format(image_path))\n                os.remove(image_path)\n        except Exception as e:\n            print(\"Issue with image {}\".format(image_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:11.918923Z","iopub.execute_input":"2024-11-05T19:01:11.9194Z","iopub.status.idle":"2024-11-05T19:01:14.869373Z","shell.execute_reply.started":"2024-11-05T19:01:11.919354Z","shell.execute_reply":"2024-11-05T19:01:14.868123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Storing all the images inside the directory to the variable \"data\".\n\ndata = tf.keras.utils.image_dataset_from_directory('/kaggle/input/final-dataset/dataset_1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:18.570344Z","iopub.execute_input":"2024-11-05T19:01:18.570848Z","iopub.status.idle":"2024-11-05T19:01:18.949592Z","shell.execute_reply.started":"2024-11-05T19:01:18.570801Z","shell.execute_reply":"2024-11-05T19:01:18.948049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_iterator = data.as_numpy_iterator()\nbatch = data_iterator.next()\ndata_iterator , batch[0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:20.183323Z","iopub.execute_input":"2024-11-05T19:01:20.183837Z","iopub.status.idle":"2024-11-05T19:01:20.309148Z","shell.execute_reply.started":"2024-11-05T19:01:20.183791Z","shell.execute_reply":"2024-11-05T19:01:20.307479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig , ax = plt.subplots(ncols = 4 , figsize = (20,20))\nfor idx , img in enumerate(batch[0][:4]):\n    ax[idx].imshow(img.astype(int))\n    ax[idx].title.set_text(batch[1][idx])\n\n# Here, Dog -> 1 & Cat -> 0.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:21.988822Z","iopub.execute_input":"2024-11-05T19:01:21.989815Z","iopub.status.idle":"2024-11-05T19:01:23.454063Z","shell.execute_reply.started":"2024-11-05T19:01:21.98975Z","shell.execute_reply":"2024-11-05T19:01:23.452597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaled = batch[0]/255\ndata = data.map(lambda x,y : (x/255 , y))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:35.463502Z","iopub.execute_input":"2024-11-05T19:01:35.463982Z","iopub.status.idle":"2024-11-05T19:01:35.510461Z","shell.execute_reply.started":"2024-11-05T19:01:35.463938Z","shell.execute_reply":"2024-11-05T19:01:35.509222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Splitting the dataset into train, validation and test data.\n\ntrain_size = int(len(data)*.7)\nval_size = int(len(data)*.2) + 1\ntest_size = int(len(data)*.1)\ntrain = data.take(train_size)\nval = data.skip(train_size).take(val_size)\ntest = data.skip(train_size + val_size).take(test_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:36.703318Z","iopub.execute_input":"2024-11-05T19:01:36.703854Z","iopub.status.idle":"2024-11-05T19:01:36.726378Z","shell.execute_reply.started":"2024-11-05T19:01:36.703808Z","shell.execute_reply":"2024-11-05T19:01:36.724577Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Question 1**\n\nNow that our dataset is well prepared, use a CNN model to learn the entire dataset. Use an appropriate number of hidden layers, flatten and dense functions along with an activation function to get the necessary output! Also, use am optimiser too.","metadata":{}},{"cell_type":"code","source":"# Answer\n\nmodel = Sequential()\nmodel.add(Conv2D(16 , (3,3) , 1 , activation='relu' , input_shape = (256,256,3)))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32 , (3,3) , 1 , activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32 , (3,3) , 1 , activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(256 , activation='relu'))\nmodel.add(Dense(1 , activation='sigmoid'))\n\nmodel.compile('adam' , loss = tf.losses.BinaryCrossentropy() , metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:39.540411Z","iopub.execute_input":"2024-11-05T19:01:39.540942Z","iopub.status.idle":"2024-11-05T19:01:39.739143Z","shell.execute_reply.started":"2024-11-05T19:01:39.540893Z","shell.execute_reply":"2024-11-05T19:01:39.737607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logdir = 'Logs'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:42.788999Z","iopub.execute_input":"2024-11-05T19:01:42.789445Z","iopub.status.idle":"2024-11-05T19:01:42.794851Z","shell.execute_reply.started":"2024-11-05T19:01:42.789404Z","shell.execute_reply":"2024-11-05T19:01:42.793527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:44.480573Z","iopub.execute_input":"2024-11-05T19:01:44.481062Z","iopub.status.idle":"2024-11-05T19:01:44.48705Z","shell.execute_reply.started":"2024-11-05T19:01:44.481015Z","shell.execute_reply":"2024-11-05T19:01:44.485621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Question\n\nTrain the dataset! :D\n\nUse an appropriate number of epochs to get the final CNN model.","metadata":{}},{"cell_type":"code","source":"# Answer\n\nhist = model.fit(train , epochs = 20 , validation_data=val , callbacks=[tensorboard_callback])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:01:46.960032Z","iopub.execute_input":"2024-11-05T19:01:46.960506Z","iopub.status.idle":"2024-11-05T19:06:50.688957Z","shell.execute_reply.started":"2024-11-05T19:01:46.960459Z","shell.execute_reply":"2024-11-05T19:06:50.68757Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Question 3**\n\nNow that your CNN model is ready, utilise the test dataset to get your final answer!","metadata":{}},{"cell_type":"code","source":"# Answer\n\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\n\n# Function to preprocess and predict for a single image\ndef preprocess_and_predict(image_path, model):\n    img = cv2.imread(image_path)\n    resize = tf.image.resize(img, (256, 256))\n    yhat = model.predict(np.expand_dims(resize.numpy() / 255.0, 0))[0][0]\n    label = 1 if yhat > 0.5 else 0\n    return label\n\n# Directory containing the test images\ntest_data_dir = '/kaggle/input/final-dataset/test'  # Replace with your test images path\n\n# Iterate over all images in the test directory (The one the kids should type)\npredictions = []\nfor img_file in os.listdir(test_data_dir):\n    img_path = os.path.join(test_data_dir, img_file)\n    label = preprocess_and_predict(img_path, model)\n    predictions.append(label)\n    print(f\"Image: {img_file}, Prediction: {label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T19:06:57.815397Z","iopub.execute_input":"2024-11-05T19:06:57.81591Z","iopub.status.idle":"2024-11-05T19:06:58.118611Z","shell.execute_reply.started":"2024-11-05T19:06:57.815863Z","shell.execute_reply":"2024-11-05T19:06:58.117437Z"}},"outputs":[],"execution_count":null}]}